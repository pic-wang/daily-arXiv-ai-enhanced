<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 5]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Differentiable Sparse Identification of Lagrangian Dynamics](https://arxiv.org/abs/2511.10706)
*Zitong Zhang,Hao Sun*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Data-driven discovery of governing equations from data remains a fundamental challenge in nonlinear dynamics. Although sparse regression techniques have advanced system identification, they struggle with rational functions and noise sensitivity in complex mechanical systems. The Lagrangian formalism offers a promising alternative, as it typically avoids rational expressions and provides a more concise representation of system dynamics. However, existing Lagrangian identification methods are significantly affected by measurement noise and limited data availability. This paper presents a novel differentiable sparse identification framework that addresses these limitations through three key contributions: (1) the first integration of cubic B-Spline approximation into Lagrangian system identification, enabling accurate representation of complex nonlinearities, (2) a robust equation discovery mechanism that effectively utilizes measurements while incorporating known physical constraints, (3) a recursive derivative computation scheme based on B-spline basis functions, effectively constraining higher-order derivatives and reducing noise sensitivity on second-order dynamical systems. The proposed method demonstrates superior performance and enables more accurate and reliable extraction of physical laws from noisy data, particularly in complex mechanical systems compared to baseline methods.

</details>


### [2] [Bias-Restrained Prefix Representation Finetuning for Mathematical Reasoning](https://arxiv.org/abs/2511.10707)
*Sirui Liang,Pengfei Cao,Jian Zhao,Cong Huang,Jun Zhao,Kang Liu*

Main category: cs.LG

TL;DR: BREP ReFT通过偏置-受限前缀表示微调来提升数学推理能力：通过裁剪训练数据以优化初始推理前缀、在早期推理阶段干预以防止错误累积、以及约束干预向量的幅度来避免干扰数值编码；在多种模型架构上显著优于标准ReFT和基于权重的PEFT。


<details>
  <summary>Details</summary>
Motivation: 现有的表示微调（ReFT）尽管在效率上优于传统PEFT，但在数学推理任务上表现显著下降，原因在于难以在推理早期阶段产生有效的前缀并且可能扰动数值编码和逐步错误累积。需要一种方法来定位并优化推理初期的关键阶段，同时保护数值编码。

Method: 提出Bias-REstrained Prefix Representation FineTuning（BREP ReFT），通过（1）裁剪训练数据以优化初始推理前缀的生成，（2）在早期推理阶段进行干预以阻断错误的累积，（3）约束干预向量的幅度以避免干扰数值编码，从而提升数学推理能力。

Result: 在多种模型架构上进行广泛实验，BREP ReFT在数学推理任务上显著优于标准ReFT和基于权重的PEFT，表现出更高的有效性、效率和鲁棒的泛化能力。

Conclusion: BREP ReFT通过聚焦推理初期阶段并对干预过程进行受控约束，成功提升了ReFT在数学推理上的表现，提供了一个对数值编码敏感的推理任务友好的微调范式。源码公开于Github。

Abstract: Parameter-Efficient finetuning (PEFT) enhances model performance on downstream tasks by updating a minimal subset of parameters. Representation finetuning (ReFT) methods further improve efficiency by freezing model weights and optimizing internal representations with fewer parameters than PEFT, outperforming PEFT on several tasks. However, ReFT exhibits a significant performance decline on mathematical reasoning tasks. To address this problem, the paper demonstrates that ReFT's poor performance on mathematical tasks primarily stems from its struggle to generate effective reasoning prefixes during the early inference phase. Moreover, ReFT disturbs the numerical encoding and the error accumulats during the CoT stage. Based on these observations, this paper proposes Bias-REstrained Prefix Representation FineTuning (BREP ReFT), which enhances ReFT's mathematical reasoning capability by truncating training data to optimize the generation of initial reasoning prefixes, intervening on the early inference stage to prevent error accumulation, and constraining the intervention vectors' magnitude to avoid disturbing numerical encoding. Extensive experiments across diverse model architectures demonstrate BREP's superior effectiveness, efficiency, and robust generalization capability, outperforming both standard ReFT and weight-based PEFT methods on the task of mathematical reasoning. The source code is available at https://github.com/LiangThree/BREP.

</details>


### [3] [Towards Uncertainty Quantification in Generative Model Learning](https://arxiv.org/abs/2511.10710)
*Giorgio Morales,Frederic Jurie,Jalal Fadili*

Main category: cs.LG

TL;DR: 提出用聚合精确率-召回曲线来量化生成模型对分布近似的不确定性，并通过集成方法比较不同架构在不确定性方面的特征。


<details>
  <summary>Details</summary>
Motivation: 当前评估多数关注学习到的分布与目标分布之间的距离，忽略对这种近似的不确定性量化与比较；需要建立不确定性量化的框架来提升对生成模型可靠性的理解。

Method:  formalize 不确定性量化在生成模型学习中的问题，探讨基于集成的精确率-召回曲线来描述分布近似的不确定性；在合成数据集进行初步实验，比较不同模型架构在不确定性方面的表现。

Result: 在合成数据集的初步实验中，聚合的精确率-召回曲线能够捕捉模型近似的不确定性，便于对不同架构在不确定性特征上的系统比较。

Conclusion: 提出一个可行的评估方向，未来工作应扩大到真实数据、理论分析和更丰富的评估指标，并探索更复杂的不确定性源。

Abstract: While generative models have become increasingly prevalent across various domains, fundamental concerns regarding their reliability persist. A crucial yet understudied aspect of these models is the uncertainty quantification surrounding their distribution approximation capabilities. Current evaluation methodologies focus predominantly on measuring the closeness between the learned and the target distributions, neglecting the inherent uncertainty in these measurements. In this position paper, we formalize the problem of uncertainty quantification in generative model learning. We discuss potential research directions, including the use of ensemble-based precision-recall curves. Our preliminary experiments on synthetic datasets demonstrate the effectiveness of aggregated precision-recall curves in capturing model approximation uncertainty, enabling systematic comparison among different model architectures based on their uncertainty characteristics.

</details>


### [4] [Movement-Specific Analysis for FIM Score Classification Using Spatio-Temporal Deep Learning](https://arxiv.org/abs/2511.10713)
*Jun Masaki,Ariaki Higashi,Naoko Shinagawa,Kazuhiko Hirata,Yuichi Kurita,Akira Furui*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The functional independence measure (FIM) is widely used to evaluate patients' physical independence in activities of daily living. However, traditional FIM assessment imposes a significant burden on both patients and healthcare professionals. To address this challenge, we propose an automated FIM score estimation method that utilizes simple exercises different from the designated FIM assessment actions. Our approach employs a deep neural network architecture integrating a spatial-temporal graph convolutional network (ST-GCN), bidirectional long short-term memory (BiLSTM), and an attention mechanism to estimate FIM motor item scores. The model effectively captures long-term temporal dependencies and identifies key body-joint contributions through learned attention weights. We evaluated our method in a study of 277 rehabilitation patients, focusing on FIM transfer and locomotion items. Our approach successfully distinguishes between completely independent patients and those requiring assistance, achieving balanced accuracies of 70.09-78.79 % across different FIM items. Additionally, our analysis reveals specific movement patterns that serve as reliable predictors for particular FIM evaluation items.

</details>


### [5] [Generalizing Fair Clustering to Multiple Groups: Algorithms and Applications](https://arxiv.org/abs/2511.11539)
*Diptarka Chakraborty,Kushagra Chatterjee,Debarati Das,Tien-Long Nguyen*

Main category: cs.LG

TL;DR: 把聚类问题扩展到多组保护属性的公平聚类，给出NP-hard性证明和近线时间近似算法，提升了公平相关聚类和公平共识聚类的近似结果，并首次给出多组情景下的近似方法。


<details>
  <summary>Details</summary>
Motivation: 解决现实中聚类对包含年龄、 ethnicity、性别等多重保护属性的群体的公平 Representation不足的问题，弥补仅在两组情形下已有解的研究空白。

Method: 证明在任意数量的组且组大小相等时，closest fair clustering NP-hard；提出近线时间的多组情形近似算法；以closest fair clustering为基，改进公平相关聚类（fair correlation clustering）的近似；首次给出多组情形下的公平共识聚类近似算法。

Result: 获得近线时间近似算法，适用于任意大小的多组数据；提高了相关与共识聚类的近似保证；解决了COLT'25和AISTATS'20等工作中的开放问题。

Conclusion: 将 closest fair clustering 从两组扩展到多组，推动公平聚类研究的理论与实践进展，为后处理公平性提供有效工具，并为多属性保护下的聚类公平性奠定基础。

Abstract: Clustering is a fundamental task in machine learning and data analysis, but it frequently fails to provide fair representation for various marginalized communities defined by multiple protected attributes -- a shortcoming often caused by biases in the training data. As a result, there is a growing need to enhance the fairness of clustering outcomes, ideally by making minimal modifications, possibly as a post-processing step after conventional clustering. Recently, Chakraborty et al. [COLT'25] initiated the study of \emph{closest fair clustering}, though in a restricted scenario where data points belong to only two groups. In practice, however, data points are typically characterized by many groups, reflecting diverse protected attributes such as age, ethnicity, gender, etc.
  In this work, we generalize the study of the \emph{closest fair clustering} problem to settings with an arbitrary number (more than two) of groups. We begin by showing that the problem is NP-hard even when all groups are of equal size -- a stark contrast with the two-group case, for which an exact algorithm exists. Next, we propose near-linear time approximation algorithms that efficiently handle arbitrary-sized multiple groups, thereby answering an open question posed by Chakraborty et al. [COLT'25].
  Leveraging our closest fair clustering algorithms, we further achieve improved approximation guarantees for the \emph{fair correlation clustering} problem, advancing the state-of-the-art results established by Ahmadian et al. [AISTATS'20] and Ahmadi et al. [2020]. Additionally, we are the first to provide approximation algorithms for the \emph{fair consensus clustering} problem involving multiple (more than two) groups, thus addressing another open direction highlighted by Chakraborty et al. [COLT'25].

</details>
