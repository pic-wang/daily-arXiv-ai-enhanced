{"id": "2602.11700", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11700", "abs": "https://arxiv.org/abs/2602.11700", "authors": ["Yongyao Wang", "Ziqi Miao", "Lu Yang", "Haonan Jia", "Wenting Yan", "Chen Qian", "Lijun Li"], "title": "TabSieve: Explicit In-Table Evidence Selection for Tabular Prediction", "comment": "13 pages", "summary": "Tabular prediction can benefit from in-table rows as few-shot evidence, yet existing tabular models typically perform instance-wise inference and LLM-based prompting is often brittle. Models do not consistently leverage relevant rows, and noisy context can degrade performance. To address this challenge, we propose TabSieve, a select-then-predict framework that makes evidence usage explicit and auditable. Given a table and a query row, TabSieve first selects a small set of informative rows as evidence and then predicts the missing target conditioned on the selected evidence. To enable this capability, we construct TabSieve-SFT-40K by synthesizing high-quality reasoning trajectories from 331 real tables using a strong teacher model with strict filtering. Furthermore, we introduce TAB-GRPO, a reinforcement learning recipe that jointly optimizes evidence selection and prediction correctness with separate rewards, and stabilizes mixed regression and classification training via dynamic task-advantage balancing. Experiments on a held-out benchmark of 75 classification and 52 regression tables show that TabSieve consistently improves performance across shot budgets, with average gains of 2.92% on classification and 4.45% on regression over the second-best baseline. Further analysis indicates that TabSieve concentrates more attention on the selected evidence, which improves robustness to noisy context.", "AI": {"tldr": "TabSieve\u63d0\u51fa\u4e00\u4e2aselect-then-predict\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u5c11\u91cf\u4fe1\u606f\u884c\u4f5c\u4e3a\u8bc1\u636e\u518d\u8fdb\u884c\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u8868\u683c\u9884\u6d4b\u5728\u5c0f\u6837\u672c\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u5b9e\u73b0\u8bc1\u636e\u7684\u53ef\u5ba1\u8ba1\u6027\u3002", "motivation": "\u73b0\u6709\u8868\u683c\u6a21\u578b\u591a\u4f9d\u8d56\u9010\u5b9e\u4f8b\u63a8\u65ad\uff0c\u57fa\u4e8eLLM\u7684\u63d0\u793a\u5bf9\u76f8\u5173\u884c\u7684\u5229\u7528\u5f80\u5f80\u4e0d\u7a33\u5b9a\uff0c\u5608\u6742\u4e0a\u4e0b\u6587\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u663e\u5f0f\u3001\u53ef\u5ba1\u8ba1\u7684\u8bc1\u636e\u9009\u62e9\u673a\u5236\u6765\u63d0\u5347\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa TabSieve\uff1a\u5148\u9009\u62e9\u4e00\u7ec4\u4fe1\u606f\u91cf\u8f83\u9ad8\u7684\u8bc1\u636e\u884c\uff0c\u518d\u5728\u9009\u5b9a\u8bc1\u636e\u7684\u6761\u4ef6\u4e0b\u8fdb\u884c\u76ee\u6807\u9884\u6d4b\u3002\u4e3a\u8bad\u7ec3\u63d0\u4f9b\u6570\u636e\u652f\u6301\uff0c\u6784\u5efa TabSieve-SFT-40K\uff1a\u4ece331\u5f20\u771f\u5b9e\u8868\u683c\u4e2d\u7528\u5f3a\u6559\u5e08\u6a21\u578b\u5408\u6210\u9ad8\u8d28\u91cf\u63a8\u7406\u8f68\u8ff9\u5e76\u8fdb\u884c\u4e25\u683c\u7b5b\u9009\u3002\u63d0\u51fa TAB-GRPO\uff1a\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u8054\u5408\u4f18\u5316\u8bc1\u636e\u9009\u62e9\u4e0e\u9884\u6d4b\u6b63\u786e\u6027\uff0c\u4e14\u901a\u8fc7\u52a8\u6001\u4efb\u52a1\u4f18\u52bf\u5e73\u8861\u6765\u7a33\u5b9a\u6df7\u5408\u56de\u5f52\u4e0e\u5206\u7c7b\u8bad\u7ec3\u3002", "result": "\u5728\u5305\u542b75\u4e2a\u5206\u7c7b\u8868\u548c52\u4e2a\u56de\u5f52\u8868\u7684 held-out \u57fa\u51c6\u4e0a\uff0cTabSieve\u5728\u5404-shot\u9884\u7b97\u4e0b\u5747\u6709\u63d0\u5347\uff0c\u76f8\u5bf9\u7b2c\u4e8c\u4f18\u57fa\u7ebf\u7684\u5e73\u5747\u589e\u76ca\u4e3a\u5206\u7c7b2.92%\u3001\u56de\u5f524.45%\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u663e\u793a\u6a21\u578b\u5bf9\u6240\u9009\u8bc1\u636e\u7684\u5173\u6ce8\u5ea6\u66f4\u9ad8\uff0c\u5bf9\u5608\u6742\u4e0a\u4e0b\u6587\u66f4\u5177\u9c81\u68d2\u6027\u3002", "conclusion": "\u8bc1\u636e\u9009\u62e9\u7684\u663e\u5f0f\u4f7f\u7528\u63d0\u5347\u4e86\u8868\u683c\u9884\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\uff0cTabSieve\u53ca\u5176\u6570\u636e\u5408\u6210\u4e0e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7b56\u7565\u4e3a\u5c0f\u6837\u672c\u573a\u666f\u4e0b\u7684\u8868\u683c\u63a8\u65ad\u63d0\u4f9b\u4e86\u6709\u6548\u8def\u5f84\u3002"}}
{"id": "2602.11738", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11738", "abs": "https://arxiv.org/abs/2602.11738", "authors": ["Ilya Kuleshov", "Alexander Marusov", "Alexey Zaytsev"], "title": "U-Former ODE: Fast Probabilistic Forecasting of Irregular Time Series", "comment": null, "summary": "Probabilistic forecasting of irregularly sampled time series is crucial in domains such as healthcare and finance, yet it remains a formidable challenge. Existing Neural Controlled Differential Equation (Neural CDE) approaches, while effective at modelling continuous dynamics, suffer from slow, inherently sequential computation, which restricts scalability and limits access to global context. We introduce UFO (U-Former ODE), a novel architecture that seamlessly integrates the parallelizable, multiscale feature extraction of U-Nets, the powerful global modelling of Transformers, and the continuous-time dynamics of Neural CDEs. By constructing a fully causal, parallelizable model, UFO achieves a global receptive field while retaining strong sensitivity to local temporal dynamics. Extensive experiments on five standard benchmarks -- covering both regularly and irregularly sampled time series -- demonstrate that UFO consistently outperforms ten state-of-the-art neural baselines in predictive accuracy. Moreover, UFO delivers up to 15$\\times$ faster inference compared to conventional Neural CDEs, with consistently strong performance on long and highly multivariate sequences.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
