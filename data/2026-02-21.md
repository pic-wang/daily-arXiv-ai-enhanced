<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Unified Latents (UL): How to train your latents](https://arxiv.org/abs/2602.17270)
*Jonathan Heek,Emiel Hoogeboom,Thomas Mensink,Tim Salimans*

Main category: cs.LG

TL;DR: 提出统一潜在表示学习框架（UL），通过将扩散先验与扩散模型解码联合正则化，获得潜在比特率的紧上界；在 ImageNet-512 与 Kinetics-600 上取得竞争/领先的生成与压缩性能。


<details>
  <summary>Details</summary>
Motivation: 在保持高质量生成与压缩效率之间寻找折中，利用扩散过程的先验信息来约束潜在表征的分布与解码行为。

Method: 将编码器输出的噪声与先验的最小噪声水平耦合，设计一个简单的训练目标，联合正则化扩散先验与扩散模型解码，得到对潜在表示的训练和估计。

Result: ImageNet-512 上的 FID 1.4，重构质量（PSNR）高且训练 FLOPs 少于基于 Stable Diffusion 潜在表示的模型；Kinetics-600 上达到 FVD 1.3 的SOTA水平。

Conclusion: UL为统一潜在表示学习提供了一种高效且质量可控的框架，理论上给出潜在比特率的紧上界，并在多数据集上展现出强的生成与压缩性能。

Abstract: We present Unified Latents (UL), a framework for learning latent representations that are jointly regularized by a diffusion prior and decoded by a diffusion model. By linking the encoder's output noise to the prior's minimum noise level, we obtain a simple training objective that provides a tight upper bound on the latent bitrate. On ImageNet-512, our approach achieves competitive FID of 1.4, with high reconstruction quality (PSNR) while requiring fewer training FLOPs than models trained on Stable Diffusion latents. On Kinetics-600, we set a new state-of-the-art FVD of 1.3.

</details>
